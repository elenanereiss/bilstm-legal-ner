{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8e99bc40",
   "metadata": {},
   "source": [
    "# How to train BiLSTM-CNN-CRF with [German LER Dataset](https://github.com/elenanereiss/Legal-Entity-Recognition)\n",
    "\n",
    "The Implementation for Sequence Tagging of [BiLSTM-CNN-CRF](https://github.com/UKPLab/emnlp2017-bilstm-cnn-crf) is used for the training. See the GitHub Repo for more information.\n",
    "> This repository contains a BiLSTM-CRF implementation that used for NLP Sequence Tagging (for example POS-tagging, Chunking, or Named Entity Recognition). The implementation is based on Keras 2.2.0 and can be run with Tensorflow 1.8.0 as backend. It was optimized for Python 3.5 / 3.6. It does not work with Python 2.7.\n",
    "\n",
    "\n",
    "# Create an environment\n",
    "\n",
    "The best way to use these models is to create an environment in conda with python 3.6:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8228b980",
   "metadata": {},
   "outputs": [],
   "source": [
    "!conda create -n ler python=3.6"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa68a0b6",
   "metadata": {},
   "source": [
    "To activate an environment:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f391c771",
   "metadata": {},
   "outputs": [],
   "source": [
    "!conda activate ler"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f4bbc66",
   "metadata": {},
   "source": [
    "# Install requirements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b01b5b8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70d008b3",
   "metadata": {},
   "source": [
    "Install tensorflow from wheel. I used the following version for Windows and python 3.6."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ce97bac",
   "metadata": {},
   "outputs": [],
   "source": [
    "wget https://raw.githubusercontent.com/fo40225/tensorflow-windows-wheel/master/1.8.0/py36/CPU/sse2/tensorflow-1.8.0-cp36-cp36m-win_amd64.whl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93d80ce1",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install tensorflow-1.8.0-cp36-cp36m-win_amd64.whl"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59aeaa3c",
   "metadata": {},
   "source": [
    "# Download dataset\n",
    "Download the [German LER Dataset](https://github.com/elenanereiss/Legal-Entity-Recognition) splits (train, dev, test) from GitHub and save it in the `data` folder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92190dd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "wget https://raw.githubusercontent.com/elenanereiss/Legal-Entity-Recognition/master/data/ler_train.conll -P data\n",
    "wget https://raw.githubusercontent.com/elenanereiss/Legal-Entity-Recognition/master/data/ler_dev.conll -P data\n",
    "wget https://raw.githubusercontent.com/elenanereiss/Legal-Entity-Recognition/master/data/ler_test.conll  -P data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "724055ce",
   "metadata": {},
   "source": [
    "# Train\n",
    "\n",
    "It is possible to use three models for training:\n",
    "- BiLSTM-CRF: modelName=`blstm-crf`;\n",
    "- BiLSTM-CRF with character embeddings from BiLSTM: modelName=`char-blstm-crf`;\n",
    "- BiLSTM-CNN-CRF with character embeddings from CNN: modelName=`blstm-cnn-crf`.\n",
    "\n",
    "I want to use `char-blstm-crf` because that model gives the best results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "411b2607",
   "metadata": {},
   "outputs": [],
   "source": [
    "from train import run_training\n",
    "\n",
    "model_name = \"char-blstm-crf\"\n",
    "train = \"data/ler_train.conll\"\n",
    "dev = \"data/ler_dev.conll\"\n",
    "test = \"data/ler_test.conll\"\n",
    "run_training(model_name, train, dev, test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2b9b2e8",
   "metadata": {},
   "source": [
    "# Evaluation\n",
    "\n",
    "To evaluate the stored model in `models/char-blstm-crf.h5`, we first need preditions from the test split `ler_test.conll`. The predictions are written in a file `ler_test_pred.conll`. After that we can get classification report on entity basis of gold labels and predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9d9c81f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from predict import write_predictions\n",
    "\n",
    "gold_labels = \"data/ler_test.conll\"\n",
    "predictions = \"data/ler_test_pred.conll\"\n",
    "model = \"models/{}.h5\".format(model_name)\n",
    "\n",
    "write_predictions(model, gold_labels, predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82c74684",
   "metadata": {},
   "outputs": [],
   "source": [
    "from evaluate import classification_report_strict\n",
    "\n",
    "classification_report_strict(gold_labels, predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c34f8b27",
   "metadata": {},
   "source": [
    "# Tagger\n",
    "\n",
    "Pretty print with tagger function via IPython."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1ee8ec3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import IPython\n",
    "import util.styles as style_config\n",
    "\n",
    "text = '''\n",
    "Ob O\n",
    "die O\n",
    "Europäische B-INN\n",
    "Kommission I-INN\n",
    "in O\n",
    "Anwendung O\n",
    "der O\n",
    "Grundsätze O\n",
    "der O\n",
    "Nr. B-EUN\n",
    "89 I-EUN\n",
    "der I-EUN\n",
    "Vertikal-Leitlinien I-EUN\n",
    "eine O\n",
    "andere O\n",
    "Auffassung O\n",
    "vertrete O\n",
    ", O\n",
    "sei O\n",
    "unerheblich O\n",
    ", O\n",
    "weil O\n",
    "es O\n",
    "bei O\n",
    "der O\n",
    "Feststellung O\n",
    "des O\n",
    "relevanten O\n",
    "Marktes O\n",
    "im O\n",
    "Sinne O\n",
    "des O\n",
    "§ B-GS\n",
    "18 I-GS\n",
    "Abs. I-GS\n",
    "1 I-GS\n",
    "GWB I-GS\n",
    "um O\n",
    "eine O\n",
    "Frage O\n",
    "des O\n",
    "nationalen O\n",
    "Rechts O\n",
    "gehe O\n",
    ". O\n",
    "\n",
    "'''\n",
    "\n",
    "\n",
    "def normalize(phrase):\n",
    "    tokens={'\" ': '\"', '( ': '(', '[ ': '[', ' )': ')', ' .': '.', ' ,': ',', ' ;': ';', ' :': ':', ' ]': ']', ' ?': '?', ' !': '!', ' /': '/', '/ ': '/'}\n",
    "    for token_with_space, token_without_space in tokens.items():\n",
    "        phrase = phrase.replace(token_with_space, token_without_space)\n",
    "    return phrase\n",
    "\n",
    "def tagger(conll_text):\n",
    "    tokens = []\n",
    "    labels = []\n",
    "    \n",
    "    for line in conll_text.split(\"\\n\"):\n",
    "        if line != \"\":\n",
    "            token, label = line.split(\" \")\n",
    "            tokens.append(token)\n",
    "            labels.append(label)\n",
    "\n",
    "    non_entity = \"\"\n",
    "    entity = \"\"\n",
    "    entity_label = \"\"\n",
    "    sentence = \"\"\n",
    "    \n",
    "    for idx in range(len(tokens)):\n",
    "        if labels[idx] == \"O\":\n",
    "            if entity != \"\":\n",
    "                sentence += '<span class=\"spark-nlp-display-entity-wrapper\" style=\"background-color: {}\"><span class=\"spark-nlp-display-entity-name\">{} </span><span class=\"spark-nlp-display-entity-type\">{}</span></span>\\n'.format(label_colors[tag], normalize(entity), tag)\n",
    "                entity = \"\"\n",
    "                entity_label = \"\"\n",
    "\n",
    "            non_entity += tokens[idx] + \" \"\n",
    "            if idx == len(tokens)-1:\n",
    "                sentence += '<span class=\"spark-nlp-display-others\" style=\"background-color: white\">{}</span>\\n'.format(normalize(non_entity))\n",
    "        else:\n",
    "            bio, tag = labels[idx].split(\"-\")\n",
    "\n",
    "            if bio == \"B\":\n",
    "                sentence += '<span class=\"spark-nlp-display-others\" style=\"background-color: white\">{} </span>\\n'.format(normalize(non_entity))\n",
    "                non_entity = \"\"\n",
    "                entity_label = tag\n",
    "\n",
    "            entity += tokens[idx] + \" \"\n",
    "            if idx == len(tokens)-1:\n",
    "                sentence += '<span class=\"spark-nlp-display-entity-wrapper\" style=\"background-color: {}\"><span class=\"spark-nlp-display-entity-name\">{}</span><span class=\"spark-nlp-display-entity-type\">{}</span></span>\\n'.format(label_colors[tag], normalize(entity), tag)\n",
    "    return sentence\n",
    "\n",
    "label_colors = style_config.COLORS\n",
    "\n",
    "html_content = tagger(text)\n",
    "html_content_save = style_config.STYLE_CONFIG_ENTITIES+ \" \" + html_content\n",
    "IPython.display.HTML(html_content_save)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
